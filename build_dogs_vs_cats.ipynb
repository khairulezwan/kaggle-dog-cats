{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import dog_vs_cats_config as config\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch.preprocessing import AspectAwarePreprocessor\n",
    "from pyimagesearch.io import HDF5DatasetWriter\n",
    "from imutils import paths\n",
    "import numpy as np \n",
    "import progressbar\n",
    "import json \n",
    "import cv2 \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the path to the image\n",
    "trainPaths = list(paths.list_images(config.IMAGES_PATH))\n",
    "trainLabels = [p.split(os.path.sep)[-2].split('.')[0]\n",
    "    for p in trainPaths]\n",
    "# For floyd [pt.split(os.path.sep)[-2] for pt in imagePaths else use (os.path.sep)[-1]]\n",
    "le = LabelEncoder()\n",
    "trainLabels = le.fit_transform(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform stratified sampling from the training set to build the\n",
    "# testing split from the training data\n",
    "split = train_test_split(trainPaths, trainLabels, test_size=config.NUM_TEST_IMAGES, stratify=trainLabels, random_state=42)\n",
    "(trainPaths, testPaths, trainLabels, testLabels) = split\n",
    "\n",
    "# perform another stratified sampling, this time to build the validation data\n",
    "split = train_test_split(trainPaths, trainLabels, test_size=config.NUM_VAL_IMAGES, stratify=trainLabels, random_state=42)\n",
    "(trainPaths, valPaths, trainLabels, valLabels) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a list pairing the training, validation and testing\n",
    "# image paths along with their corresponding labels and outputs HDF5\n",
    "# files\n",
    "datasets = [\n",
    "    ('train', trainPaths, trainLabels, config.TRAIN_HDF5),\n",
    "    ('val', valPaths, valLabels, config.VAL_HDF5),\n",
    "    ('test', testPaths, testLabels, config.TEST_HDF5)]\n",
    "\n",
    "# init the image preprocessor and the list of RGB channel\n",
    "# averages\n",
    "aap = AspectAwarePreprocessor(256,256)\n",
    "(R,G,B) = ([],[],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Dataset:   0% |                                       | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building HDF5/train.hdf5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Dataset: 100% |########################################| Time: 0:02:58\n",
      "Building Dataset:   0% |                                       | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building HDF5/val.hdf5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Dataset: 100% |########################################| Time: 0:00:22\n",
      "Building Dataset:   0% |                                       | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building HDF5/test.hdf5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Dataset: 100% |########################################| Time: 0:00:23\n"
     ]
    }
   ],
   "source": [
    "# loop over the dataset tuples\n",
    "for(dType, paths, labels, outputPath) in datasets:\n",
    "    # create HDF5 writer\n",
    "    print(\"[INFO] building {}...\".format(outputPath))\n",
    "    writer = HDF5DatasetWriter((len(paths), 256, 256, 3), outputPath)\n",
    "\n",
    "    # init the progress bar\n",
    "    widgets = [\"Building Dataset: \", progressbar.Percentage(), \" \",progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "    pbar = progressbar.ProgressBar(maxval=len(paths), widgets=widgets).start()\n",
    "\n",
    "\n",
    "    # loop over the image path\n",
    "    for (i, (path, label)) in enumerate (zip(paths, labels)):\n",
    "        # load the image and process it\n",
    "        image = cv2.imread(path)\n",
    "        image = aap.preprocess(image)\n",
    "\n",
    "        # if we are building the training dataset, then compute the\n",
    "        # mean of each channel in the image, then update the\n",
    "        # respective lists\n",
    "\n",
    "        if dType == \"train\":\n",
    "            (b,g,r) = cv2.mean(image)[:3]\n",
    "            R.append(r)\n",
    "            G.append(g)\n",
    "            B.append(b)\n",
    "\n",
    "        # add the image and label # to the HDF5 dataset\n",
    "        writer.add([image], [label])\n",
    "        pbar.update(i)\n",
    "\n",
    "    # close the HDF5  writer\n",
    "    pbar.finish()\n",
    "    writer.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing image...\n"
     ]
    }
   ],
   "source": [
    "# construct a dictionary of averages, then serializes the means to a JSON file\n",
    "print(\"[INFO] serializing image...\")\n",
    "D = {\"R\": np.mean(R), \"G\":np.mean(G), \"B\":np.mean(B)}\n",
    "f = open(config.DATASET_MEAN, 'w')\n",
    "f.write(json.dumps(D))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
