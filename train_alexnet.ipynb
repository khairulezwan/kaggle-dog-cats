{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "# set matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from config import dog_vs_cats_config as config\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import SimplePreprocessor\n",
    "from pyimagesearch.preprocessing import PatchPreProcessor\n",
    "from pyimagesearch.preprocessing import MeanPreProcessor\n",
    "from pyimagesearch.callbacks import TrainingMonitor\n",
    "from pyimagesearch.io import HDF5DataSetGenerator\n",
    "from pyimagesearch.nn.conv import AlexNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data aug\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the RGB means for the training set\n",
    "means = json.loads(open(config.DATASET_MEAN).read())\n",
    "\n",
    "# init the image preprocess\n",
    "sp = SimplePreprocessor(227,227)\n",
    "pp = PatchPreProcessor(227, 227)\n",
    "mp = MeanPreProcessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the training and val dataset generators\n",
    "trainGen = HDF5DataSetGenerator(config.TRAIN_HDF5, 128, aug=aug,\n",
    "preprocessors=[pp,mp,iap], classes=2)\n",
    "valGen = HDF5DataSetGenerator(config.VAL_HDF5, 128,\n",
    "preprocessors=[pp,mp,iap], classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the optimizers\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model = AlexNet.build(width=227, height=227, depth=3, classes=2, reg=0.0002)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizers=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# construct the set of call backs\n",
    "path = os.path.sep.join([config.OUTPUT_PATH, \"{}.png\".format(os.getpid())])\n",
    "callbacks = [TrainingMonitor(path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "model.fit_generator(\n",
    "    trainGen.generator(),\n",
    "    steps_per_epoch=trainGen.numImages // 128,\n",
    "    validation_data=valGen.generator(),\n",
    "    validation_steps=valGen.numImages // 128,\n",
    "    epochs=75,\n",
    "    max_queue_size=10,\n",
    "    callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(config.MODEL_PATH, overwrite=True)\n",
    "\n",
    "# close the HDF5 datasets\n",
    "trainGen.close()\n",
    "valGen.close()"
   ]
  }
 ]
}